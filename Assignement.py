# -*- coding: utf-8 -*-
"""Copy of kon_giorgas_debug.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gpytTD04t1OfJBsdp5QCG_3PVhSI5Rdi

"""# Mounting Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""# Libraries"""

# Commented out IPython magic to ensure Python compatibility.
import os
import re
import h5py
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from PIL import Image
from skimage import transform
import pymongo
import shutil
from sklearn.neighbors import NearestNeighbors
from keras.utils.vis_utils import plot_model
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# %matplotlib inline
print(tf.__version__)

model = load_model("/content/drive/My Drive/model_88.h5")

# Preparing the dataset and organising it in folders
this entire process was performed locally. The folders were created locally and then they were uploaded to google drive

Loading file and inspecting the initial dataset
"""

labels_csv = pd.read_csv('D:/Dataset/fashion-product-images-small/styles.csv',
                  error_bad_lines=False)

print(labels_csv.shape)
print (labels_csv.head())

"""We are going to use the top 8 categories of subCategories"""

frequent_sub = pd.crosstab(index=labels_csv["subCategory"],columns="count").sort_values("count", ascending=False)
frequent_sub

labels_range = ['Topwear','Shoes','Bags',
                'Bottomwear','Watches','Innerwear',
                'Jewellery','Eyewear','Socks']
                               
dataset = labels_csv.loc[labels_csv['subCategory'].isin(labels_range),['id', 'subCategory']]

dataset.index = range(len(dataset.index))
print(dataset.shape)
print(dataset)

round(100*len(dataset)/len(labels_csv),2)

dataset['subCategory'].value_counts()

"""By diminishing the number of categories we managed to keep 80% of the data

We have desided to split our dataset accordingly: 60% training set 20% test set 20% validation set
"""

data_set = ["train", "test", "validate"]
weights = [0.6, 0.2, 0.2]

"""We created folders of each category and dumped there the files"""

for i in ["train", "test", "validate"]:
    os.mkdir('D:/Dataset/fashion-product-images-small/segments/' + i)
    for y in labels_range:
        os.mkdir('D:/Dataset/fashion-product-images-small/segments/' + i + '/' + y)

non_existent = []
for i in range(len(dataset)):
    if os.path.isfile('D:/Dataset/fashion-product-images-small/images/' + str(dataset.id[i]) + '.jpg'):
        shutil.copy('D:/Dataset/fashion-product-images-small/images/' + str(dataset.id[i]) + '.jpg',
                    'D:/Dataset/fashion-product-images-small/segments/' + ''.join(choices(data_set, weights)) + '/' + dataset.subCategory[i])
    else:
        non_existent.append(dataset.id[i])

"""There were 5 items present on the csv with the labels that were not present on the image dataset"""

non_existent

"""# Functions"""

def plot_images(ims, figsize = (12, 6), rows = 1, interp = False, titles = None):
    if type(ims[0]) is np.ndarray:
        ims = np.array(ims).astype(np.uint8)
        if (ims.shape[-1] != 3):
            ims = ims.transpose((0,2,3,1))
    f = plt.figure(figsize = figsize)
    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1
    for i in range(len(ims)):
        sp = f.add_subplot(rows, cols, i + 1)
        sp.axis('Off')
        if titles is not None:
            sp.set_title(titles[i], fontsize = 6)
        plt.imshow(ims[i], interpolation = None if interp else 'none')

def nearest_neighbors(values, all_values, nbr_neighbors=11):
    nn = NearestNeighbors(nbr_neighbors, metric='cosine', algorithm='brute').fit(np.array(all_values.tolist()))
    dists, idxs = nn.kneighbors([values])
    return(idxs[0])

def imagepreparation(filename):
  np_image = Image.open(filename)
  np_image = np.array(np_image).astype('float32')
  np_image = transform.resize(np_image, (80, 80, 3))
  np_image = np.expand_dims(np_image, axis=0)
  return np_image

imagetovec = K.function([model.layers[0].input],
                                  [model.layers[9].output])

def build_model2():
  seq_model2 = Sequential([
      # ======================= FIRST FILTER # =======================
      Conv2D(32, (3, 3), input_shape=(80, 80, 3), activation = 'relu'),
      MaxPooling2D(pool_size=(2, 2), padding = 'same'),
      # ======================= SECOND FILTER  =======================
      Conv2D(32, (3, 3), activation = 'relu'),
      MaxPooling2D(pool_size=(2, 2), padding = 'same'),
      # ======================= THIRD FILTER  ========================
      Conv2D(64, (3, 3), activation = 'relu'),
      MaxPooling2D(pool_size=(2, 2), padding = 'same'),
      # ======================= FLATTEN - DENSE LAYERS =======================
      Flatten(),
      Dense(128, activation = 'relu'),
      Dense(64, activation = 'relu'),
      Dropout(0.5),
      Dense(N_LABELS, activation='softmax')
  ])
  
  print(seq_model2.summary())
  return seq_model2

"""# Training the model"""

base_path ='/content/drive/My Drive/Colab Notebooks/data/segments'

train_path = os.path.join(base_path, 'train')
validate_path = os.path.join(base_path, 'validate')
test_path = os.path.join(base_path, 'test')



LABELS = sorted(['Topwear', 'Shoes', 'Bags',
                 'Bottomwear', 'Watches', 'Innerwear',
                 'Jewellery', 'Eyewear', 'Socks'])

IMG_SIZE = (80, 80)
BATCH_SIZE = 256

N_LABELS = len(LABELS)

IMG_SIZE, BATCH_SIZE, N_LABELS

train_batches = ImageDataGenerator(
    rotation_range=70,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.20,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest',
    rescale=1.0 / 255.0).flow_from_directory(train_path,
                                             #shuffle=True,
                                             target_size=IMG_SIZE,
                                             classes=LABELS,
                                             batch_size=BATCH_SIZE,
                                             class_mode='categorical')

valid_batches = ImageDataGenerator(
    rescale=1.0 / 255.0).flow_from_directory(validate_path,
                                             #shuffle=True,
                                             target_size=IMG_SIZE,
                                             classes=LABELS,
                                             batch_size=BATCH_SIZE, #biger batches in validation because stas do not su, up too well when small
                                             class_mode='categorical')

test_batches = ImageDataGenerator(
    rescale=1.0 / 255.0).flow_from_directory(test_path,
                                             target_size=IMG_SIZE,
                                             classes=LABELS,
                                             batch_size=BATCH_SIZE,
                                             class_mode='categorical')

model = build_model2()

opt = Adam(lr=0.0001)

model.compile(optimizer=opt,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=12, verbose=0,
                          mode='auto', baseline=None, restore_best_weights=True)

history = model.fit_generator(train_batches,
                              steps_per_epoch=100,
                              validation_data=valid_batches,
                              validation_steps=25,
                              epochs=50)

model.summary()

model.predict(test_batches)

model.save("/content/drive/My Drive/Colab Notebooks/model_88.h5")

tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

# summarize history for accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

"""# Mongo - image to vector
correct way

MOving all images to a common repository
"""

path = '/content/drive/My Drive/Colab Notebooks/data/segments/'
files = []
category = []
for r, d, f in os.walk(path):
    for file in f:
        if '.jpg' in file:
            path = os.path.join(r, file)
            shutil.move(path,"/content/drive/My Drive/Colab Notebooks/testingdir/"+file)

client = pymongo.MongoClient("mongodb://admin:admin@minime-shard-00-00-jmbfg.mongodb.net:27017,minime-shard-00-01-jmbfg.mongodb.net:27017,minime-shard-00-02-jmbfg.mongodb.net:27017/test?ssl=true&replicaSet=MiniMe-shard-0&authSource=admin&retryWrites=true&w=majority")

db = client['Clothes']

collection = db['ClothesRepository']

path = '/content/drive/My Drive/Colab Notebooks/testingdir/'

files = []
for r, d, f in os.walk(path):
    for file in f:
        if '.jpg' in file:
            files.append(os.path.join(r, file))

for f in files:
  image = imagepreparation(f)
  image_category = int(np.argmax(model.predict(image)))
  image_array = list(np.around(np.array(imagetovec([image])[0].tolist()[0]),2))
  image_code = int(re.split("\.|/", f)[-2])
  mydict = { "Category": image_category, "id": image_code ,"vector": image_array}
  collection.insert_one(mydict)

"""creating index on Category field ascending"""

resp = colection.create_index([ ("Category", 1) ])
print ("index response:", resp)

"""# Nearest Neighbours"""

def recommend_me(img):
  clothe = imagepreparation(img)
  print("The image you submitted")
  plot_images(clothe)
  vec = list(np.around(np.array(imagetovec([clothe])[0].tolist()[0]),2))
  cat = int(np.argmax(model.predict(clothe)))
  cursor = collection.find({"Category": cat})
  same_cat =  pd.DataFrame(list(cursor)).iloc[:,[2,3]]
  similar = nearest_neighbors(vec, same_cat.iloc[:,1])
  print("The 10 most similar clothes")
  for i in similar:
    plot_images(imagepreparation("/content/drive/My Drive/Colab Notebooks/testingdir/" + str(same_cat.iloc[i,0]) + ".jpg"))

#for example
recommend_me("/content/drive/My Drive/Colab Notebooks/testingdir/1163.jpg")
