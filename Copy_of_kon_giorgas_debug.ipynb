{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of kon_giorgas_debug.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JY7qsXoytiJt",
        "MN-KsBgma7KN",
        "hM95-OCxa32W",
        "5iksVUruawuW",
        "QWMnjrnLS7aX",
        "peNQBWDfIAfm",
        "9gtovsCNoQyI"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonstantinosGiorgas/Big_Data_Content_Analytics_Assignement/blob/master/Copy_of_kon_giorgas_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7qsXoytiJt",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the dataset and organising it in folders\n",
        "this entire process was performed locally. The folders were created locally and then they were uploaded to google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWKFTwfatlA9",
        "colab_type": "text"
      },
      "source": [
        "Loading file and inspecting the initial dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6JujKu3trPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_csv = pd.read_csv('D:/Dataset/fashion-product-images-small/styles.csv',\n",
        "                  error_bad_lines=False)\n",
        "\n",
        "print(labels_csv.shape)\n",
        "print (labels_csv.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtVEATqvtz-A",
        "colab_type": "text"
      },
      "source": [
        "We are going to use the top 8 categories of subCategories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX__dyigt2VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frequent_sub = pd.crosstab(index=labels_csv[\"subCategory\"],columns=\"count\").sort_values(\"count\", ascending=False)\n",
        "frequent_sub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYftyHIuCEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_range = ['Topwear','Shoes','Bags',\n",
        "                'Bottomwear','Watches','Innerwear',\n",
        "                'Jewellery','Eyewear','Socks']\n",
        "                               \n",
        "dataset = labels_csv.loc[labels_csv['subCategory'].isin(labels_range),['id', 'subCategory']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL0QhtsmuGGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.index = range(len(dataset.index))\n",
        "print(dataset.shape)\n",
        "print(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01ATtYW3uK3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "round(100*len(dataset)/len(labels_csv),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD0hvTQlytZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['subCategory'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKM3pQTWuOij",
        "colab_type": "text"
      },
      "source": [
        "By diminishing the number of categories we managed to keep 80% of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gXTFIXyuUAT",
        "colab_type": "text"
      },
      "source": [
        "We have desided to split our dataset accordingly: 60% training set 20% test set 20% validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6bUOalTuQxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_set = [\"train\", \"test\", \"validate\"]\n",
        "weights = [0.6, 0.2, 0.2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX1jnMufudfM",
        "colab_type": "text"
      },
      "source": [
        "We created folders of each category and dumped there the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siBIbVZZuYcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in [\"train\", \"test\", \"validate\"]:\n",
        "    os.mkdir('D:/Dataset/fashion-product-images-small/segments/' + i)\n",
        "    for y in labels_range:\n",
        "        os.mkdir('D:/Dataset/fashion-product-images-small/segments/' + i + '/' + y) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gztgjbNulLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_existent = []\n",
        "for i in range(len(dataset)):\n",
        "    if os.path.isfile('D:/Dataset/fashion-product-images-small/images/' + str(dataset.id[i]) + '.jpg'):\n",
        "        shutil.copy('D:/Dataset/fashion-product-images-small/images/' + str(dataset.id[i]) + '.jpg',\n",
        "                    'D:/Dataset/fashion-product-images-small/segments/' + ''.join(choices(data_set, weights)) + '/' + dataset.subCategory[i])\n",
        "    else:\n",
        "        non_existent.append(dataset.id[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Mtk97OupIq",
        "colab_type": "text"
      },
      "source": [
        "There were 5 items present on the csv with the labels that were not present on the image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsYi1tBrurUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_existent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN-KsBgma7KN",
        "colab_type": "text"
      },
      "source": [
        "# Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34h4sFU_M_BN",
        "colab_type": "code",
        "outputId": "ae447fda-284a-420c-bc7c-06d9103b4bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM95-OCxa32W",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENIOiwpDM_Gz",
        "colab_type": "code",
        "outputId": "c712c966-300b-4b81-a16b-ba2dfbc880cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from skimage import transform\n",
        "import pymongo\n",
        "import shutil\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p6J8tSbcPl1",
        "colab_type": "code",
        "outputId": "a1d7b2ca-adad-41cd-c006-d2fab315775b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "model = load_model(\"/content/drive/My Drive/model_88.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iksVUruawuW",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ38rk-dUYiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_images(ims, figsize = (12, 6), rows = 1, interp = False, titles = None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize = figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i + 1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize = 6)\n",
        "        plt.imshow(ims[i], interpolation = None if interp else 'none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOhRdSoUZyRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nearest_neighbors(values, all_values, nbr_neighbors=11):\n",
        "    nn = NearestNeighbors(nbr_neighbors, metric='cosine', algorithm='brute').fit(np.array(all_values.tolist()))\n",
        "    dists, idxs = nn.kneighbors([values])\n",
        "    return(idxs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYsQVtzeZbZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imagepreparation(filename):\n",
        "  np_image = Image.open(filename)\n",
        "  np_image = np.array(np_image).astype('float32')\n",
        "  np_image = transform.resize(np_image, (80, 80, 3))\n",
        "  np_image = np.expand_dims(np_image, axis=0)\n",
        "  return np_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2yw0BXF2Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagetovec = K.function([model.layers[0].input],\n",
        "                                  [model.layers[9].output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTIlbrABl1XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model2():\n",
        "  seq_model2 = Sequential([\n",
        "      # ======================= FIRST FILTER # =======================\n",
        "      Conv2D(32, (3, 3), input_shape=(80, 80, 3), activation = 'relu'),\n",
        "      MaxPooling2D(pool_size=(2, 2), padding = 'same'),\n",
        "      # ======================= SECOND FILTER  =======================\n",
        "      Conv2D(32, (3, 3), activation = 'relu'),\n",
        "      MaxPooling2D(pool_size=(2, 2), padding = 'same'),\n",
        "      # ======================= THIRD FILTER  ========================\n",
        "      Conv2D(64, (3, 3), activation = 'relu'),\n",
        "      MaxPooling2D(pool_size=(2, 2), padding = 'same'),\n",
        "      # ======================= FLATTEN - DENSE LAYERS =======================\n",
        "      Flatten(),\n",
        "      Dense(128, activation = 'relu'),\n",
        "      Dense(64, activation = 'relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(N_LABELS, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "  print(seq_model2.summary())\n",
        "  return seq_model2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWMnjrnLS7aX",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "535EVw_FNdH8",
        "colab_type": "code",
        "outputId": "12c93285-a87d-4f18-c032-c700ec82abce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "base_path ='/content/drive/My Drive/Colab Notebooks/data/segments'\n",
        "\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "validate_path = os.path.join(base_path, 'validate')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "\n",
        "\n",
        "\n",
        "LABELS = sorted(['Topwear', 'Shoes', 'Bags',\n",
        "                 'Bottomwear', 'Watches', 'Innerwear',\n",
        "                 'Jewellery', 'Eyewear', 'Socks'])\n",
        "\n",
        "IMG_SIZE = (80, 80)\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "N_LABELS = len(LABELS)\n",
        "\n",
        "IMG_SIZE, BATCH_SIZE, N_LABELS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80, 80), 256, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-ZwfMBNoQX",
        "colab_type": "code",
        "outputId": "02203ece-701b-4f3e-859d-386e78a4fd88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_batches = ImageDataGenerator(\n",
        "    rotation_range=70,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.20,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1.0 / 255.0).flow_from_directory(train_path,\n",
        "                                             #shuffle=True,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             classes=LABELS,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode='categorical')\n",
        "\n",
        "valid_batches = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0).flow_from_directory(validate_path,\n",
        "                                             #shuffle=True,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             classes=LABELS,\n",
        "                                             batch_size=BATCH_SIZE, #biger batches in validation because stas do not su, up too well when small\n",
        "                                             class_mode='categorical')\n",
        "\n",
        "test_batches = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0).flow_from_directory(test_path,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             classes=LABELS,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21459 images belonging to 9 classes.\n",
            "Found 6333 images belonging to 9 classes.\n",
            "Found 7139 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnphpSPsNsNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQf6OOf4M_Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr=0.0001)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=12, verbose=0,\n",
        "                          mode='auto', baseline=None, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKU0PS4ZM_MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=100,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=25,\n",
        "                              epochs=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFjNFEVjaMpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XB-yR7DT_1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(test_batches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00YCOlAztLnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Colab Notebooks/model_88.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbdXvEmERzrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Gvi3izfIx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2dI5vVZfNje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peNQBWDfIAfm",
        "colab_type": "text"
      },
      "source": [
        "# mongo - image to vector\n",
        "correct way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olR3oKUgJddD",
        "colab_type": "text"
      },
      "source": [
        "MOving all images to a common repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS3FIiQ5JcaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/data/segments/'\n",
        "files = []\n",
        "category = []\n",
        "for r, d, f in os.walk(path):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            path = os.path.join(r, file)\n",
        "            shutil.move(path,\"/content/drive/My Drive/Colab Notebooks/testingdir/\"+file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44MAm_XvIKv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = pymongo.MongoClient(\"mongodb://admin:admin@minime-shard-00-00-jmbfg.mongodb.net:27017,minime-shard-00-01-jmbfg.mongodb.net:27017,minime-shard-00-02-jmbfg.mongodb.net:27017/test?ssl=true&replicaSet=MiniMe-shard-0&authSource=admin&retryWrites=true&w=majority\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bndqj8NzIPdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = client['Clothes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqhSzfnyITIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db['ClothesRepository']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48WL7gcn8XLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/testingdir/'\n",
        "\n",
        "files = []\n",
        "for r, d, f in os.walk(path):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            files.append(os.path.join(r, file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYcZItzCGu87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in files:\n",
        "  image = imagepreparation(f)\n",
        "  image_category = int(np.argmax(model.predict(image)))\n",
        "  image_array = list(np.around(np.array(imagetovec([image])[0].tolist()[0]),2))\n",
        "  image_code = int(re.split(\"\\.|/\", f)[-2])\n",
        "  mydict = { \"Category\": image_category, \"id\": image_code ,\"vector\": image_array}\n",
        "  collection.insert_one(mydict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXcNqReOkONt",
        "colab_type": "text"
      },
      "source": [
        "creating index on Category field ascending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RzwO4Q4kUjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resp = colection.create_index([ (\"Category\", 1) ])\n",
        "print (\"index response:\", resp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfs6qNqbCMqz",
        "colab_type": "code",
        "outputId": "6ce28f17-6e0e-4c2d-b758-5f0790e3904b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "#load the model\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/model_88.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 16:40:02.404298 140078249105280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0905 16:40:02.405915 140078249105280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0905 16:40:02.408287 140078249105280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gtovsCNoQyI",
        "colab_type": "text"
      },
      "source": [
        "# Nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FxAFFZymbEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recommend_me(img):\n",
        "  clothe = imagepreparation(img)\n",
        "  plot_images(clothe)\n",
        "  vec = list(np.around(np.array(imagetovec([clothe])[0].tolist()[0]),2))\n",
        "  cat = int(np.argmax(model.predict(clothe)))\n",
        "  cursor = collection.find({\"Category\": cat})\n",
        "  same_cat =  pd.DataFrame(list(cursor)).iloc[:,[2,3]]\n",
        "  similar = nearest_neighbors(vec, same_cat.iloc[:,1])\n",
        "  for i in similar:\n",
        "    plot_images(imagepreparation(\"/content/drive/My Drive/Colab Notebooks/testingdir/\" + str(same_cat.iloc[i,0]) + \".jpg\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7xaeKycpFBn",
        "colab_type": "code",
        "outputId": "a29d55b8-e8f3-44c1-a45e-564cbeef8bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "recommend_me(\"/content/drive/My Drive/Colab Notebooks/testingdir/1163.jpg\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ebd1c2899387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommend_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/testingdir/1163.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-f756a7087e82>\u001b[0m in \u001b[0;36mrecommend_me\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecommend_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mclothe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimagepreparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclothe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagetovec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclothe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclothe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-25ad3965b25f>\u001b[0m in \u001b[0;36mimagepreparation\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimagepreparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/Colab Notebooks/testingdir/1163.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYZsivsYTXB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = imagepreparation(\"/content/drive/My Drive/Colab Notebooks/testingdir/1653.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcEnnx6EUgTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_images(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRsVRrfDfsaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = list(np.around(np.array(imagetovec([image])[0].tolist()[0]),2))\n",
        "cat = int(np.argmax(model.predict(image)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt861Qybf9lD",
        "colab_type": "code",
        "outputId": "a366f816-fd35-4d21-d1bc-86b05d8e8755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(cat, vec)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 [499.82, 0.0, 691.25, 0.0, 450.58, 0.0, 1250.39, 334.94, 0.0, 50.5, 0.0, 0.0, 441.84, 0.0, 0.0, 216.54, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1135.62, 32.07, 1106.17, 626.33, 1258.2, 0.0, 576.54, 1012.5, 221.37, 0.0, 0.0, 0.0, 287.57, 1218.78, 0.0, 0.0, 54.04, 0.0, 0.0, 916.37, 0.0, 0.0, 0.0, 817.69, 0.0, 490.53, 0.0, 397.07, 0.0, 0.0, 0.0, 0.0, 0.0, 864.79, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tC00mZKTCKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a query to the specific DB and Collection\n",
        "cursor = collection.find({\"Category\": cat})\n",
        "\n",
        "# Expand the cursor and construct the DataFrame\n",
        "df =  pd.DataFrame(list(cursor))\n",
        "df2 = df.iloc[:,[2,3]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5RHVBsQE7tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id = nearest_neighbors(vec, df2.iloc[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u8z8cbKVcMe",
        "colab_type": "code",
        "outputId": "7b0bd634-9e66-426d-afc7-6586b71888c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df2.iloc[id,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "649      1653\n",
              "604     36837\n",
              "365     12839\n",
              "594     47637\n",
              "1653    36141\n",
              "373     39745\n",
              "1911    36211\n",
              "122     27955\n",
              "641     13374\n",
              "1625    35247\n",
              "1       36200\n",
              "Name: id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31qy9WdqVajc",
        "colab_type": "code",
        "outputId": "5353181e-9db4-4718-bf8a-e819b3355bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "for i in id:\n",
        "  plot_images(imagepreparation(\"/content/drive/My Drive/testingdir/\" + str(df2.iloc[i,0]) + \".jpg\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1c9e05baadee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagepreparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/testingdir/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-25ad3965b25f>\u001b[0m in \u001b[0;36mimagepreparation\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimagepreparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/testingdir/36901.jpg'"
          ]
        }
      ]
    }
  ]
}