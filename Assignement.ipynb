{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of kon_giorgas_debug.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JY7qsXoytiJt",
        "MN-KsBgma7KN",
        "5iksVUruawuW",
        "peNQBWDfIAfm",
        "olR3oKUgJddD",
        "42h9Kf1fpH1c",
        "XmP_v6CppX2F",
        "9gtovsCNoQyI"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonstantinosGiorgas/Big_Data_Content_Analytics_Assignement/blob/master/Assignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7qsXoytiJt",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the dataset and organising it in folders\n",
        "this entire process was performed locally. The folders were created locally and then they were uploaded to google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWKFTwfatlA9",
        "colab_type": "text"
      },
      "source": [
        "Loading file and inspecting the initial dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6JujKu3trPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_csv = pd.read_csv('D:/Dataset/fashion-product-images-small/styles.csv',\n",
        "                  error_bad_lines=False)\n",
        "\n",
        "print(labels_csv.shape)\n",
        "print (labels_csv.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtVEATqvtz-A",
        "colab_type": "text"
      },
      "source": [
        "We are going to use the top 8 categories of subCategories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX__dyigt2VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frequent_sub = pd.crosstab(index=labels_csv[\"subCategory\"],columns=\"count\").sort_values(\"count\", ascending=False)\n",
        "frequent_sub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYftyHIuCEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_range = ['Topwear','Shoes','Bags',\n",
        "                'Bottomwear','Watches','Innerwear',\n",
        "                'Jewellery','Eyewear','Socks']\n",
        "                               \n",
        "dataset = labels_csv.loc[labels_csv['subCategory'].isin(labels_range),['id', 'subCategory']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL0QhtsmuGGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.index = range(len(dataset.index))\n",
        "print(dataset.shape)\n",
        "print(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01ATtYW3uK3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "round(100*len(dataset)/len(labels_csv),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD0hvTQlytZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['subCategory'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKM3pQTWuOij",
        "colab_type": "text"
      },
      "source": [
        "By diminishing the number of categories we managed to keep 80% of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gXTFIXyuUAT",
        "colab_type": "text"
      },
      "source": [
        "We have desided to split our dataset accordingly: 60% training set 20% test set 20% validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6bUOalTuQxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_set = [\"train\", \"test\", \"validate\"]\n",
        "weights = [0.6, 0.2, 0.2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX1jnMufudfM",
        "colab_type": "text"
      },
      "source": [
        "We created folders of each category and dumped there the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siBIbVZZuYcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in [\"train\", \"test\", \"validate\"]:\n",
        "    os.mkdir('D:/Dataset/fashion-product-images-small/segments/' + i)\n",
        "    for y in labels_range:\n",
        "        os.mkdir('D:/Dataset/fashion-product-images-small/segments/' + i + '/' + y) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gztgjbNulLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_existent = []\n",
        "for i in range(len(dataset)):\n",
        "    if os.path.isfile('D:/Dataset/fashion-product-images-small/images/' + str(dataset.id[i]) + '.jpg'):\n",
        "        shutil.copy('D:/Dataset/fashion-product-images-small/images/' + str(dataset.id[i]) + '.jpg',\n",
        "                    'D:/Dataset/fashion-product-images-small/segments/' + ''.join(choices(data_set, weights)) + '/' + dataset.subCategory[i])\n",
        "    else:\n",
        "        non_existent.append(dataset.id[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Mtk97OupIq",
        "colab_type": "text"
      },
      "source": [
        "There were 5 items present on the csv with the labels that were not present on the image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsYi1tBrurUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_existent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01fQP3Zr2hu3",
        "colab_type": "text"
      },
      "source": [
        "Ater all the steps in this section were successfully completed I uploaded all the folders to google drive so they can be accesible from the collab notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN-KsBgma7KN",
        "colab_type": "text"
      },
      "source": [
        "# Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34h4sFU_M_BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Xp4Kn_00lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM95-OCxa32W",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENIOiwpDM_Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from skimage import transform\n",
        "import pymongo\n",
        "import shutil\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJwoLNqZyhxK",
        "colab_type": "text"
      },
      "source": [
        "This function load the model we have already tained and can be founf on the flask app folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p6J8tSbcPl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(\"/content/drive/My Drive/Colab Notebooks/model_88.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iksVUruawuW",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mYhuzi_wwd-",
        "colab_type": "text"
      },
      "source": [
        "In this step we initiate all the required functions to work with in our project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrmvshojxmW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "This function plots and displays an image in the collab notebook environment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ38rk-dUYiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_images(ims, figsize = (12, 6), rows = 1, interp = False, titles = None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize = figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i + 1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize = 6)\n",
        "        plt.imshow(ims[i], interpolation = None if interp else 'none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB3noEtOx7Qh",
        "colab_type": "text"
      },
      "source": [
        "This function given an array return the indexes of the 10 most similar arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOhRdSoUZyRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nearest_neighbors(values, all_values, nbr_neighbors=10):\n",
        "    nn = NearestNeighbors(nbr_neighbors, metric='cosine', algorithm='brute').fit(np.array(all_values.tolist()))\n",
        "    dists, idxs = nn.kneighbors([values])\n",
        "    return(idxs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty1YbXRHx9LJ",
        "colab_type": "text"
      },
      "source": [
        "This functions makes all the necessary preprocessing so an image can be fed to our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYsQVtzeZbZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imagepreparation(filename):\n",
        "  np_image = Image.open(filename)\n",
        "  np_image = np.array(np_image).astype('float32')\n",
        "  np_image = transform.resize(np_image, (80, 80, 3))\n",
        "  np_image = np.expand_dims(np_image, axis=0)\n",
        "  return np_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8S5LR5pyIUZ",
        "colab_type": "text"
      },
      "source": [
        "This function returns the output of the second to last layer. The \"feature array\" of an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2yw0BXF2Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagetovec = K.function([model.layers[0].input],\n",
        "                                  [model.layers[9].output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwpl1NqEyX4p",
        "colab_type": "text"
      },
      "source": [
        "This functions builts the simple yet effective model for our problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTIlbrABl1XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model2():\n",
        "  seq_model2 = Sequential([\n",
        "      # ======================= FIRST FILTER # =======================\n",
        "      Conv2D(32, (3, 3), input_shape=(80, 80, 3), activation = 'relu'),\n",
        "      MaxPooling2D(pool_size=(2, 2), padding = 'same'),\n",
        "      # ======================= SECOND FILTER  =======================\n",
        "      Conv2D(32, (3, 3), activation = 'relu'),\n",
        "      MaxPooling2D(pool_size=(2, 2), padding = 'same'),\n",
        "      # ======================= THIRD FILTER  ========================\n",
        "      Conv2D(64, (3, 3), activation = 'relu'),\n",
        "      MaxPooling2D(pool_size=(2, 2), padding = 'same'),\n",
        "      # ======================= FLATTEN - DENSE LAYERS =======================\n",
        "      Flatten(),\n",
        "      Dense(128, activation = 'relu'),\n",
        "      Dense(64, activation = 'relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(N_LABELS, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "  print(seq_model2.summary())\n",
        "  return seq_model2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWMnjrnLS7aX",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsKQ70NVp1gd",
        "colab_type": "text"
      },
      "source": [
        "In this step we set the paths and the categories we are going to use in the training of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "535EVw_FNdH8",
        "colab_type": "code",
        "outputId": "f019be80-c82a-4111-e907-51cfb183343b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "base_path ='/content/drive/My Drive/Colab Notebooks/data/segments'\n",
        "\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "validate_path = os.path.join(base_path, 'validate')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "\n",
        "\n",
        "\n",
        "LABELS = sorted(['Topwear', 'Shoes', 'Bags',\n",
        "                 'Bottomwear', 'Watches', 'Innerwear',\n",
        "                 'Jewellery', 'Eyewear', 'Socks'])\n",
        "\n",
        "IMG_SIZE = (80, 80)\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "N_LABELS = len(LABELS)\n",
        "\n",
        "IMG_SIZE, BATCH_SIZE, N_LABELS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80, 80), 256, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILvrqcWKp9p9",
        "colab_type": "text"
      },
      "source": [
        "In this step we create the generators so our image data can flow from their directories to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-ZwfMBNoQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = ImageDataGenerator(\n",
        "    rotation_range=70,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.20,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1.0 / 255.0).flow_from_directory(train_path,\n",
        "                                             #shuffle=True,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             classes=LABELS,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode='categorical')\n",
        "\n",
        "valid_batches = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0).flow_from_directory(validate_path,\n",
        "                                             #shuffle=True,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             classes=LABELS,\n",
        "                                             batch_size=BATCH_SIZE, #biger batches in validation because stas do not su, up too well when small\n",
        "                                             class_mode='categorical')\n",
        "\n",
        "test_batches = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0).flow_from_directory(test_path,\n",
        "                                             target_size=IMG_SIZE,\n",
        "                                             classes=LABELS,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMnc4c6iqTxG",
        "colab_type": "text"
      },
      "source": [
        "Building and training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnphpSPsNsNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQf6OOf4M_Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr=0.0001)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=12, verbose=0,\n",
        "                          mode='auto', baseline=None, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKU0PS4ZM_MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=100,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=25,\n",
        "                              epochs=50,\n",
        "                             callbacks = earlystop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFjNFEVjaMpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azgtqOWPqKVe",
        "colab_type": "text"
      },
      "source": [
        "Saving the model for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00YCOlAztLnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Colab Notebooks/model_88.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcBcvnAhqPkO",
        "colab_type": "text"
      },
      "source": [
        "Ploting model training statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbdXvEmERzrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Gvi3izfIx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2dI5vVZfNje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peNQBWDfIAfm",
        "colab_type": "text"
      },
      "source": [
        "# Mongo - image to vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olR3oKUgJddD",
        "colab_type": "text"
      },
      "source": [
        "### With this script we passed all the images divides in train-test-validate and categories subfolders to a common folder that would act as image pool for our recommendation system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS3FIiQ5JcaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/data/segments/'\n",
        "files = []\n",
        "category = []\n",
        "for r, d, f in os.walk(path):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            path = os.path.join(r, file)\n",
        "            shutil.move(path,\"/content/drive/My Drive/Colab Notebooks/testingdir/\"+file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42h9Kf1fpH1c",
        "colab_type": "text"
      },
      "source": [
        "### With the scripts below we establish a connection with the collection in Mongo where all image features are stored"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44MAm_XvIKv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = pymongo.MongoClient(\"mongodb://admin:admin@minime-shard-00-00-jmbfg.mongodb.net:27017,minime-shard-00-01-jmbfg.mongodb.net:27017,minime-shard-00-02-jmbfg.mongodb.net:27017/test?ssl=true&replicaSet=MiniMe-shard-0&authSource=admin&retryWrites=true&w=majority\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bndqj8NzIPdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = client['Clothes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqhSzfnyITIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection = db['ClothesRepository']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmP_v6CppX2F",
        "colab_type": "text"
      },
      "source": [
        "### With the scripts bellow we pass all available images through our model so it can predict a category and a features vector for each one while saven both in Mongo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48WL7gcn8XLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/testingdir/'\n",
        "\n",
        "files = []\n",
        "for r, d, f in os.walk(path):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            files.append(os.path.join(r, file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYcZItzCGu87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in files:\n",
        "  image = imagepreparation(f)\n",
        "  image_category = int(np.argmax(model.predict(image)))\n",
        "  image_array = list(np.around(np.array(imagetovec([image])[0].tolist()[0]),2))\n",
        "  image_code = int(re.split(\"\\.|/\", f)[-2])\n",
        "  mydict = { \"Category\": image_category, \"id\": image_code ,\"vector\": image_array}\n",
        "  collection.insert_one(mydict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXcNqReOkONt",
        "colab_type": "text"
      },
      "source": [
        "An index was created automatically by Mongo on Category field so we do not need to create one. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gtovsCNoQyI",
        "colab_type": "text"
      },
      "source": [
        "# Nearest Neighbours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLcBxKEEoQ60",
        "colab_type": "text"
      },
      "source": [
        "This function plots the image we gave as input and then the 10 most similar images to this picture by similarty descending. If we give it as input an image already in the data base then the most similar image would be the picture we gave it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FxAFFZymbEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recommend_me(img):\n",
        "  clothe = imagepreparation(img)\n",
        "  plot_images(clothe)\n",
        "  vec = list(np.around(np.array(imagetovec([clothe])[0].tolist()[0]),2))\n",
        "  cat = int(np.argmax(model.predict(clothe)))\n",
        "  cursor = collection.find({\"Category\": cat})\n",
        "  same_cat =  pd.DataFrame(list(cursor)).iloc[:,[2,3]]\n",
        "  similar = nearest_neighbors(vec, same_cat.iloc[:,1])\n",
        "  for i in similar:\n",
        "    plot_images(imagepreparation(\"/content/drive/My Drive/Colab Notebooks/testingdir/\" + str(same_cat.iloc[i,0]) + \".jpg\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7xaeKycpFBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recommend_me(\"/content/drive/My Drive/Colab Notebooks/testingdir/1697.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}